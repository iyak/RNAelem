#!/usr/bin/env python
#usage: elem -h
from argparse import ArgumentParser
from itertools import groupby
from math import isnan
from numpy import mean,log,unique,max,sum,transpose,exp,fromiter,float64
from os.path import exists
from pathlib import Path
from random import seed,shuffle
from re import compile
from subprocess import Popen,PIPE
from sys import stdout,stderr,version_info
from textwrap import dedent
inf,nan=float("inf"),float("nan")

### Setting for grid engine
ge={
    "cmd"    :"qsub",                            # command to submit a job
    "array"  :"-t 1-:N:",                        # :N: represents number of array-jobs
    "cwd"    :"-cwd",                            # option to set cwd as working directory
    "envvar" :"-V",                              # option to pass environment variables
    "stdout" :"-o :file:",                       # :file: is the file to write stdout
    "stderr" :"-e :file:",                       # :file: is the file to write stderr
    "shell"  :"-S $SHELL",                       # option to set current shell as interpreter
    "memory" :"-l mem_req=:mem:G,s_vmem=:mem:G", # :mem: is memory to use
    "cpu"    :"-pe def_slot :cpu:",              # :cpu: is num of cpu to use
    "task_id":"SGE_TASK_ID",                     # env var to store task ID
    "sync"   :"-sync y",                         # option to wait until job terminates
    "other"  :"",                                # any other options you want to specify
    }

### Util
def cry(*x):
    stderr.write(" ".join(map(str,x))+'\n')
def die(*x):
    cry(*x)
    exit()
def _run(cmd,stdin=None):
    cry("sh:",dedent(cmd))
    if not None==stdin:cry(dedent(stdin))
    p=Popen(cmd,shell=True,stdout=PIPE,stderr=PIPE,stdin=PIPE)
    o,e=p.communicate(stdin.encode("utf-8") if not None==stdin else None)
    return o.decode("utf-8"),e.decode("utf-8")
def run(cmd,stdin=None):
    o,e=_run(cmd,stdin)
    stdout.write(o)
    stderr.write(e)
    return o,e
def nlines(fname):
    count=0
    for _ in open(fname):count+=1
    return count
def n_fa(faname):
    count=0
    for l in open(faname):count+=1 if '>'==l[0] else 0
    return count
def chunk(x,n):
    j,r=0,[]
    for w in [len(x)//n+int(i<len(x)%n) for i in range(n)]:
        r+=[x[j:j+w]]
        j+=w
    return r
def parse_fasta(fasta_name):
    fh=open(fasta_name)
    faiter=(x[1] for x in groupby(fh,lambda l:'>'==l[0]))
    for header in faiter:
        header=header.__next__()[1:].strip()
        seq="".join(s.strip() for s in faiter.__next__())
        yield header,seq
def parse_raw(raw):
    with open(raw) as fi:
        while True:
            try:yield dict(fi.readline().strip().split(": ",1) for _ in range(10))
            except:return
def aggregate(LL,fns,key=0,val=None):
    if None==val:val=list(range(1,len(LL)))
    if len(LL)!=(len(fns)+1):raise RuntimeError("%d!=%d"%(len(LL),len(fns)+1))
    res=[[] for _ in range(len(LL))]
    for k in unique(LL[key]):
        res[0]+=[k]
        vals=[[] for _ in val]
        for i in range(len(LL[key])):
            if LL[key][i]==k:
                for j,v in enumerate(val):
                    vals[j]+=[LL[v][i]]
        for i,val_fn in enumerate(zip(vals,fns),start=1):
            v,fn=val_fn
            if"mean"==fn:res[i]+=[mean(fromiter(v,dtype=float))]
            elif"comma"==fn:res[i]+=[','.join(map(str,v))]
            elif"sum"==fn:res[i]+=[sum(fromiter(v,dtype=float))]
            elif"max"==fn:res[i]+=[max(fromiter(v,dtype=float))]
            elif"min"==fn:res[i]+=[min(fromiter(v,dtype=float))]
            elif"logsumexp"==fn:res[i]+=[sum(exp(fromiter(v,dtype=float)))/len(v)]
    return res
def calc_AUC(ox,score):
    if len(ox)!=len(score):
        raise RuntimeError("%d!=%d"%(len(ox),len(score)))
    score,o,n=aggregate([score,ox,[1]*len(ox)],["sum","sum"])
    tp,fp,tn,fn=sum(o),sum(n)-sum(o),0,0
    x,y,AUC=1.,1.,0.
    for si,oi,ni in sorted(zip(score,o,n)):
        if isnan(si): continue
        tp,fn,fp,tn=tp-oi,fn+oi,fp-(ni-oi),tn+(ni-oi)
        FPR,TPR=float64(fp)/(tn+fp),float64(tp)/(tp+fn)
        AUC+=(x-FPR)*(y+TPR)/2.
        x,y=FPR,TPR
    return AUC+x*y/2.

### Application
parser=ArgumentParser(description="Tool to discover RNA structural motif element")
sub_parser=parser.add_subparsers(dest="subcommand",help="subcommand")
parser_init=sub_parser.add_parser("init",help="initialize training")
parser_train=sub_parser.add_parser("train",help="train the motif model by dataset")
parser_select=sub_parser.add_parser("select",help="select the best pattern")
parser_refine=sub_parser.add_parser("refine",help="train the motif model for more data and iterations")
parser_scan=sub_parser.add_parser("scan",help="scan the motif model over dataset")
parser_pipeline=sub_parser.add_parser("pipeline",help="run pipeline using grid engine")
### pipeline
parser_pipeline.add_argument("-p","--positive",metavar="FASTA",default=None,
        help="positive sequence set", required=True)
parser_pipeline.add_argument("-n","--negative",metavar="FASTA",default=None,
        help="negative sequence set")
parser_pipeline.add_argument("-m","--pattern-list",metavar="FILE",default=None,
        help="pattern list to search; one per line", required=True)
parser_pipeline.add_argument("-o","--outdir",metavar="DIR",default="elem_out",
        help="directory name to save outputs to")
parser_pipeline.add_argument("-F","--force-overwrite",action="store_true",
        help="force overwrite if outdir already exists")
parser_pipeline.add_argument("-k","--kfold-cv",metavar="INT",default=2,type=int,
        help="k of k-fold cross validation")
parser_pipeline.add_argument("-w","--max-span",metavar="INT",default=50,
        help="max distance for bases to make a pair")
parser_pipeline.add_argument("-i","--max-iter",metavar="INT",default=300,
        help="max iteration count")
parser_pipeline.add_argument("-t","--thread",metavar="INT",default=1,
        help="number of threads")
parser_pipeline.add_argument("-a","--array",action="store_true",
        help="enable array job")
parser_pipeline.add_argument("-b","--batch-size",metavar="INT",default=64,type=int,
        help="size of mini-batch")
parser_pipeline.add_argument("--no-shuffle",action="store_true",
        help="Train without generating shuffled negative sequences.")
parser_pipeline.add_argument("-N","--num-motifs",metavar="INT",default=3,type=int,
        help="number of motif candidates")
parser_pipeline.add_argument("-P","--plot-base-threshold",metavar="FLOAT",default=1.5,type=float,
        help="When plotting 2D diagram of a motif, bases are specified for the loci with less sequential entropy with this threshold")
### options for init
parser_init.add_argument("-p","--positive",metavar="FASTA",default=None,
        help="positive sequence set",required=True)
parser_init.add_argument("-n","--negative",metavar="FASTA",default=None,
        help="negative sequence set")
parser_init.add_argument("-m","--pattern-list",metavar="FILE",default=None,
        help="pattern list to search; one per line",required=True)
parser_init.add_argument("-o","--outdir",metavar="DIR",default="elem_out",
        help="directory name to save outputs to")
parser_init.add_argument("-F","--force-overwrite",action="store_true",
        help="force overwrite if outdir already exists")
parser_init.add_argument("-k","--kfold-cv",metavar="INT",default=2,type=int,
        help="k of k-fold cross validation")
### options for train
parser_train.add_argument("-M","--elem-out",metavar="DIR",default=None,
        help="elem output dir",
        required=True)
parser_train.add_argument("--pattern-index",metavar="INT",default=None,type=int,
        help="set to perform training only for specific search pattern in the list (1-origin)")
parser_train.add_argument("-w","--max-span",metavar="INT",default=50,
        help="max distance for bases to make a pair")
parser_train.add_argument("-i","--max-iter",metavar="INT",default=300,
        help="max iteration count")
parser_train.add_argument("-t","--thread",metavar="INT",default=1,
        help="number of threads")
parser_train.add_argument("-a","--array",action="store_true",
        help="enable array job")
parser_train.add_argument("-b","--batch-size",metavar="INT",default=64,type=int,
        help="size of mini-batch")
parser_train.add_argument("--no-shuffle",action="store_true",
        help="Train without generating shuffled negative sequences.")
### option for select
parser_select.add_argument("-M","--elem-out",metavar="DIR",default=None,
        help="elem output dir that includes multiple motif model files in it",
        required=True)
parser_select.add_argument("-N","--num-motifs",metavar="INT",default=3,type=int,
        help="number of motif candidates")
### option for refine
parser_refine.add_argument("-M","--elem-out",metavar="DIR",default=None,
        help="elem output dir",required=True)
parser_refine.add_argument("--pattern-index",metavar="INT",default=None,
        help="index of motif model to be refined")
parser_refine.add_argument("-i","--max-iter",metavar="INT",default=300,
        help="max iteration count")
parser_refine.add_argument("-a","--array",action="store_true",
        help="enable array job")
parser_refine.add_argument("-t","--thread",metavar="INT",default=1,
        help="number of threads")
parser_refine.add_argument("--no-shuffle",action="store_true",
        help="refine without generating shuffled negative sequences")
parser_refine.add_argument("-b","--batch-size",metavar="INT",default=64,type=int,
        help="size of mini-batch")
parser_refine.add_argument("-P","--plot-base-threshold",metavar="FLOAT",default=1.5,type=float,
        help="When plotting 2D diagram of a motif, bases are specified for the loci with less sequential entropy with this threshold")
### option for scan
parser_scan.add_argument("-s","--sequence",metavar="FASTA",default=None,
        help="sequence set to search motifs",required=True)
model=parser_scan.add_mutually_exclusive_group(required=True)
model.add_argument("-m","--model",metavar="FILE",default=None,
        help="motif model file")
model.add_argument("-M","--elem-out",metavar="DIR",default=None,
        help="elem output dir that includes multiple motif model files in it")
parser_scan.add_argument("-o","--outdir",metavar="DIR",default="scan_out",
        help="directory name to save outputs to")
parser_scan.add_argument("-t","--thread",metavar="INT",default=1,
        help="number of threads")
parser_scan.add_argument("-a","--array",action="store_true",
        help="enable array job")
parser_scan.add_argument("-F","--force-overwrite",action="store_true",
        help="force overwrite if outdir already exists")
options=vars(parser.parse_args())
if "outdir" in options:
    if exists(options["outdir"]) and not options["force_overwrite"]:
        die("already exists:",options["outdir"])
if "kfold_cv" in options:
    if options["kfold_cv"]<2:
        die("kfold_cv must be greater than 1:",options["kfold_cv"])
if "num_motifs" in options:
    if "pattern_list" in options:
        fname=options["pattern_list"]
    else:
        fname=f"{options['elem_out']}/pattern_list"
    nl=len([p.strip() for p in open(fname) if p.strip()])
    if nl<options["num_motifs"]:
        cry("num-motifs cannot be larger than number of patterns:",options["num_motifs"])
        cry("set to number of patterns:",nl)
        options["num_motifs"]=nl

### RNAelem callers
def get_folds_patterns(elem_out):
    o,e=_run("find {elem_out} -name cv-* -type d".format(**locals()))
    folds=[k.split('cv-')[-1].strip('/') for k in o.strip().split('\n')]
    o,e=_run("find {elem_out}/cv-{k}/train -name pattern-* -type d".format(k=folds[0],**locals()))
    patterns=[p.split('pattern-')[-1].strip('/') for p in o.strip().split('\n')]
    return folds,patterns
def cross_divide_inputs(positive,negative,kfold_cv,outdir):
    for k in range(kfold_cv):run("mkdir -p {outdir}/cv-{k}".format(**locals()))
    seed(positive)
    folds_posi=list(range(n_fa(positive)))
    folds_nega=list(range(n_fa(negative))) if negative else None
    shuffle(folds_posi)
    if negative:shuffle(folds_nega)
    fasta={"posi":positive,"nega":negative}
    folds={
            "posi":list(map(sorted,chunk(folds_posi,kfold_cv))),
            "nega":list(map(sorted,chunk(folds_nega,kfold_cv))) if negative else None
            }
    fps=[{
        "posi":{
            "train":open("{outdir}/cv-{k}/train.positive.fa".format(outdir=outdir,k=k),'w'),
            "test":open("{outdir}/cv-{k}/test.positive.fa".format(outdir=outdir,k=k),'w')},
        "nega":None if None==negative else{
            "train":open("{outdir}/cv-{k}/train.negative.fa".format(outdir=outdir,k=k),'w'),
            "test":open("{outdir}/cv-{k}/test.negative.fa".format(outdir=outdir,k=k),'w')}
        }for k in range(kfold_cv)]
    for pn in ["posi","nega"] if negative else ["posi"]:
        ii=[0 for _ in range(kfold_cv)]
        for i,record in enumerate(parse_fasta(fasta[pn])):
            for kk,fold in enumerate(folds[pn]):
                if i==fold[ii[kk]]:
                    fps[kk][pn]["test"].write(">{}\n{}\n".format(*record))
                    if ii[kk]<len(folds[pn][kk])-1:ii[kk]+=1
                    else:# reach end of fold
                        fps[kk][pn]["test"].close()
                else:
                    fps[kk][pn]["train"].write(">{}\n{}\n".format(*record))
        for kk,_ in enumerate(folds[pn]):
            fps[kk][pn]["train"].close()
def gen_cv_summary(elem_out):
    folds,patterns=get_folds_patterns(elem_out)
    with open(f"{elem_out}/cv","w") as cv:
        for k in folds:
            for tid in patterns:
                llik=0.
                AUC=0.5
                try:
                    llik+=sum([log(float(r["exist prob"])) for r in
                            parse_raw(f"{elem_out}/cv-{k}/test/pattern-{tid}/positive.raw")])
                    if exists("{elem_out}/cv-{k}/test/negative.raw".format(**locals())):
                        llik+=sum([log(1-float(r["exist prob"])) for r in
                                parse_raw(f"{elem_out}/cv-{k}/test/pattern-{tid}/negative.raw")])
                    AUC=calc_AUC_raw(
                            f"{elem_out}/cv-{k}/test/pattern-{tid}/positive.raw",
                            f"{elem_out}/cv-{k}/test/pattern-{tid}/negative.raw")
                except Exception as e:
                    cry("k_fold,pattern:",k,tid)
                    cry("error:",e)
                cv.write(f"{k}\t{tid}\t{llik}\t{AUC}\n")
    cry("written:","{elem_out}/cv".format(**locals()))
def calc_AUC_raw(positive,negative):
    ox,score=zip(*[[1,float(r["exist prob"])] for r in parse_raw(positive)]
            +[[0,float(r["exist prob"])] for r in parse_raw(negative)])
    return calc_AUC(ox,score)

def run_rnaelem_init(positive, negative, pattern_list, outdir, kfold_cv, **_):
    run(f"mkdir -p {outdir}")
    if None==negative:
        cry("info: generate negative sequence by 2mer shuffling")
        run(f"dishuffle.py {positive} >{outdir}/negative.fa")
        negative=f"{outdir}/negative.fa"
    _run(f"kmer-psp.py {positive} {negative} > {outdir}/train.fq 2>> {outdir}/log")
    cross_divide_inputs(positive,negative,kfold_cv,outdir)
    run(f"cp {pattern_list} {outdir}/pattern_list")
    for k in range(kfold_cv):
        run(f"mkdir -p {outdir}/cv-{k}/train {outdir}/cv-{k}/test")
        run(' '.join(["kmer-psp.py",f"{outdir}/cv-{k}/train.positive.fa",
            "" if None==negative else f"{outdir}/cv-{k}/train.negative.fa",
            ">",f"{outdir}/cv-{k}/train/train.fq","2>>",outdir+"/log",
            ]))
        run(' '.join(["kmer-psp.py",f"{outdir}/cv-{k}/test.positive.fa",
            ">",f"{outdir}/cv-{k}/test/positive.fq","2>>",outdir+"/log",
            ]))
        run(' '.join(["kmer-psp.py",f"{outdir}/cv-{k}/test.negative.fa",
            ">",f"{outdir}/cv-{k}/test/negative.fq","2>>",outdir+"/log",
            ]))
def run_rnaelem_train(elem_out, max_span, max_iter, batch_size, thread, array, pattern_index, no_shuffle, **_):
    kfold_cv=len(get_folds_patterns(elem_out)[0])
    pattern_list=f"{elem_out}/pattern_list"
    no_shuffle = "--no-shuffle" if no_shuffle else ""
    if array:
        _run(' '.join([ge["cmd"],
            ge["cwd"],ge["envvar"],ge["shell"],ge["sync"],ge["other"],
            ge["array"].replace(":N:",str(nlines(elem_out+"/pattern_list")*kfold_cv)),
            ge["stdout"].replace(":file:",elem_out+"/grid.stdout"),
            ge["stderr"].replace(":file:",elem_out+"/grid.stderr"),
            ge["memory"].replace(":mem:",str(4)),
            ge["cpu"].replace(":cpu:",str(thread)),
            ]),
            stdin=f"""
tid=${ge["task_id"]}
i_motif=`expr '(' $tid '-' 1 ')' '/' {kfold_cv} '+' 1`
k=`expr '(' $tid - 1 ')' % {kfold_cv}`
motif=`sed "$i_motif q;d" '{elem_out}/pattern_list'`
mkdir -p {elem_out}/cv-$k/train/pattern-$i_motif
mkdir -p {elem_out}/cv-$k/test/pattern-$i_motif
RNAelem --fastq {elem_out}/cv-$k/train/train.fq\
        --max-span {max_span}\
        --motif-pattern $motif\
        --thread {thread}\
        --max-iter {max_iter}\
        --batch-size {batch_size}\
        {no_shuffle}\
        --out1 {elem_out}/cv-$k/train/pattern-$i_motif/train.model\
        --out2 {elem_out}/cv-$k/train/pattern-$i_motif/train.raw\
        --out3 {elem_out}/cv-$k/train/pattern-$i_motif/train.interim\
        2>> {elem_out}/cv-$k/train/pattern-$i_motif/log
RNAelem scan\
        --fastq {elem_out}/cv-$k/test/positive.fq\
        --motif-model {elem_out}/cv-$k/train/pattern-$i_motif/train.model\
        --thread {thread}\
        --out1 {elem_out}/cv-$k/test/pattern-$i_motif/positive.raw\
        2>> {elem_out}/cv-$k/test/pattern-$i_motif/log
RNAelem scan\
        --fastq {elem_out}/cv-$k/test/negative.fq\
        --motif-model {elem_out}/cv-$k/train/pattern-$i_motif/train.model\
        --thread {thread}\
        --out1 {elem_out}/cv-$k/test/pattern-$i_motif/negative.raw\
        2>> {elem_out}/cv-$k/test/pattern-$i_motif/log""")
    else:
        if pattern_index is None:
            indices=range(1,1+nlines(pattern_list))
        else:
            indices=[pattern_index]
        for pattern_index in indices:
            for k in range(kfold_cv):
                cry("k_fold:",k)
                cry("pattern:",pattern_index)
                _run(f"""
motif=`sed "{pattern_index} q;d" '{elem_out}/pattern_list'`
mkdir -p {elem_out}/cv-{k}/train/pattern-{pattern_index}
mkdir -p {elem_out}/cv-{k}/test/pattern-{pattern_index}
RNAelem --fastq {elem_out}/cv-{k}/train/train.fq\
        --max-span {max_span}\
        --motif-pattern $motif\
        --thread {thread}\
        --max-iter {max_iter}\
        --batch-size {batch_size}\
        {no_shuffle}\
        --out1 {elem_out}/cv-{k}/train/pattern-{pattern_index}/train.model\
        --out2 {elem_out}/cv-{k}/train/pattern-{pattern_index}/train.raw\
        --out3 {elem_out}/cv-{k}/train/pattern-{pattern_index}/train.interim\
        2>> {elem_out}/cv-{k}/train/pattern-{pattern_index}/log
RNAelem scan\
        --fastq {elem_out}/cv-{k}/test/positive.fq\
        --motif-model {elem_out}/cv-{k}/train/pattern-{pattern_index}/train.model\
        --thread {thread}\
        --out1 {elem_out}/cv-{k}/test/pattern-{pattern_index}/positive.raw\
        2>> {elem_out}/cv-{k}/test/pattern-{pattern_index}/log
RNAelem scan\
        --fastq {elem_out}/cv-{k}/test/negative.fq\
        --motif-model {elem_out}/cv-{k}/train/pattern-{pattern_index}/train.model\
        --thread {thread}\
        --out1 {elem_out}/cv-{k}/test/pattern-{pattern_index}/negative.raw\
        2>> {elem_out}/cv-{k}/test/pattern-{pattern_index}/log""")
def run_rnaelem_select(elem_out, num_motifs, **_):
    run(f"mkdir -p {elem_out}/summary")
    fname=elem_out+"/pattern_list"
    patterns=["#margin to make 1-origin"]+[p.strip() for p in open(fname)]
    gen_cv_summary(elem_out)
    o,_=_run(" ".join(["awk '$3<0&&\"nan\"!=$3'",elem_out+"/cv"]))
    d_orig=[l.strip().split('\t') for l in o.strip().split('\n')]
    #columns of d_orig: (0)CV ID / (1)pattern id / (2)log likelihood / (3)AUC
    d_aggr=aggregate(transpose(d_orig),fns=["comma","sum","mean"],key=1,val=[0,2,3])
    print(d_aggr)
    #columns of d_aggr: (0)pattern id / (1)CV IDs / (2)log likelihood / (3)AUC
    p_prim=[d for d in transpose(d_aggr) if "_" in patterns[int(d[0])]]
    if 0<len(p_prim):
        p0=sorted(p_prim,key=lambda x:float(x[3]),reverse=True)[0]
        cv_best=sorted([d for d in d_orig if d[1]==p0[0]],key=lambda x:float(x[3]))[-1][0]
        run(f"""
cp\
        {elem_out}/cv-{cv_best}/train/pattern-{p0[0]}/train.model\
        {elem_out}/summary/model-prim.txt""")
    p_scnd=[d for d in transpose(d_aggr) if not "_" in patterns[int(d[0])]]
    p_rank=sorted(p_scnd,key=lambda x:float(x[3]),reverse=True)[:num_motifs]
    for i,p in enumerate(p_rank):
        cv_best=sorted([d for d in d_orig if d[1]==p[0]],key=lambda x:float(x[3]))[-1][0]
        run(f"""
cp\
        {elem_out}/cv-{cv_best}/train/pattern-{p[0]}/train.model\
        {elem_out}/summary/model-{i+1}.txt""")
def run_rnaelem_refine(elem_out, max_iter, batch_size, plot_base_threshold, array, thread, pattern_index, no_shuffle, **_):
    no_shuffle = "--no-shuffle" if no_shuffle else ""
    models=[str(p) for p in Path(f"{elem_out}/summary").glob("model-*.txt")]
    if array:
        _run(' '.join([ge["cmd"],
            ge["cwd"],ge["envvar"],ge["shell"],ge["sync"],ge["other"],
            ge["array"].replace(":N:",str(nlines(elem_out+"/pattern_list"))),
            ge["stdout"].replace(":file:",elem_out+"/grid.stdout"),
            ge["stderr"].replace(":file:",elem_out+"/grid.stderr"),
            ge["memory"].replace(":mem:",str(8)),
            ge["cpu"].replace(":cpu:",str(thread)),
            ]),
            stdin=f"""
tid=${ge["task_id"]}
models=({" ".join(["padding"] + models)})
model=${{models[tid]}}
tmp=$(basename -- "$model")
model_base="${{tmp%.*}}"
mkdir -p {elem_out}/${{model_base}}
RNAelem --fastq {elem_out}/train.fq\
        --motif-model ${{model}}\
        --max-iter {max_iter}\
        --batch-size {batch_size}\
        --thread {thread}\
        {no_shuffle}\
        --out1 {elem_out}/${{model_base}}/train.model\
        --out2 {elem_out}/${{model_base}}/train.raw\
        --out3 {elem_out}/${{model_base}}/train.interim\
        2>> {elem_out}/${{model_base}}/log
draw_motif.py\
        {elem_out}/${{model_base}}\
        {elem_out}/${{model_base}}/rss.eps\
        {elem_out}/${{model_base}}/prf.svg\
        {plot_base_threshold}
rsvg-convert\
        -f png --background-color=white\
        -o {elem_out}/${{model_base}}/prf.png\
        {elem_out}/${{model_base}}/prf.svg
convert\
        -density 320\
        {elem_out}/${{model_base}}/rss.eps\
        {elem_out}/${{model_base}}/rss.png""")
    else:
        if pattern_index is not None:
            models=[models[pattern_index-1]]
        for model in models:
            model_stem=Path(model).stem
            _run(f"""
mkdir -p {elem_out}/{model_stem}
RNAelem --fastq {elem_out}/train.fq\
        --motif-model {model}\
        --max-iter {max_iter}\
        --batch-size {batch_size}\
        --thread {thread}\
        {no_shuffle}\
        --out1 {elem_out}/{model_stem}/train.model\
        --out2 {elem_out}/{model_stem}/train.raw\
        --out3 {elem_out}/{model_stem}/train.interim\
        2>> {elem_out}/{model_stem}/log
draw_motif.py\
        {elem_out}/{model_stem}\
        {elem_out}/{model_stem}/rss.eps\
        {elem_out}/{model_stem}/prf.svg\
        {plot_base_threshold}
rsvg-convert\
        -f png --background-color=white\
        -o {elem_out}/{model_stem}/prf.png\
        {elem_out}/{model_stem}/prf.svg
convert\
        -density 320\
        {elem_out}/{model_stem}/rss.eps\
        {elem_out}/{model_stem}/rss.png""")
def run_rnaelem_scan(model,elem_out,sequence,outdir,array,thread,**_):
    run(f"mkdir -p {outdir}")
    run(" ".join(["kmer-psp.py",sequence,
        ">",outdir+"/scan.fq","2>>",outdir+"/log"]))
    if model is None:#directory was given
        _,patterns=get_folds_patterns(elem_out)
        _run(" ".join([
            "find",elem_out+"/pattern-*",
            "-name","train.model"]))[0].strip().split('\n')
        tids=" ".join(patterns)
        if array:
            _run(" ".join([ge["cmd"],
                ge["array"].replace(":N:",patterns),
                ge["cwd"],ge["envvar"],ge["shell"],ge["sync"],ge["other"],
                ge["stdout"].replace(":file:",outdir+"/grid.stdout"),
                ge["stderr"].replace(":file:",outdir+"/grid.stderr"),
                ge["memory"].replace(":mem:",str(8)),
                ge["cpu"].replace(":cpu:",str(thread)),
                ]),
                stdin=f"""
tids=(0 {tids}) #0 is to make a margin
tid=${{tids[{ge["task_id"]}]}}
mkdir -p {outdir}/pattern-$tid
RNAelem scan\
    --fastq {outdir}/scan.fq\
    --motif-model {elem_out}/pattern-$tid/train.model\
    --thread {thread}\
    --out1 {outdir}/pattern-$tid/scan.raw\
    2> {outdir}/pattern-$tid/log""")
        else:
            _run(f"""
for tid in {tids}
do
    mkdir -p {outdir}/pattern-$tid
    RNAelem scan\
        --fastq {outdir}/scan.fq\
        --motif-model {elem_out}/pattern-$tid/train.model\
        --thread {thread}\
        --out1 {outdir}/pattern-$tid/scan.raw\
        2> {outdir}/pattern-$tid/log
done""")
    elif elem_out is None:#file was given
        _run(f"""
RNAelem scan\
    --fastq {outdir}/scan.fq\
    --motif-model {model}\
    --thread {thread}\
    --out1 {outdir}/scan.raw\
    2>> {outdir}/log""")
    else:raise RuntimeError("unknown model format")

### Main
if version_info[0]<3:
    die("must be using Python 3")
if "pipeline"==options["subcommand"]:
    run_rnaelem_init(**options)
    options["elem_out"]=options["outdir"]
    options["pattern_index"]=None
    run_rnaelem_train(**options)
    run_rnaelem_select(**options)
    run_rnaelem_refine(**options)
elif "init"==options["subcommand"]:
    run_rnaelem_init(**options)
elif "train"==options["subcommand"]:
    run_rnaelem_train(**options)
elif "select"==options["subcommand"]:
    run_rnaelem_select(**options)
elif "refine"==options["subcommand"]:
    run_rnaelem_refine(**options)
elif "scan"==options["subcommand"]:
    run_rnaelem_scan(**options)
else:
    die("unknown subcommand:",options["subcommand"])
